{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f8e2015-9b7f-410c-bf75-d30e61dcbb79",
   "metadata": {},
   "source": [
    "# **ReelFeel - IMDB Reviews Sentiment Classification Model with Natural Language Processing - using Recurrent Neural Networks**\n",
    "\n",
    "---\n",
    "\n",
    "**Alam Rincon - [GitHub: MrRincon](https://github.com/MrRincon)**\n",
    "\n",
    "**Petar Atanasov - [GitHub: petar-Atanasov](https://github.com/petar-Atanasov)**\n",
    "\n",
    "**Teon Morgan - [GitHub: Mi1kDev](https://github.com/Mi1kDev)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef32349-f6c6-48a0-b099-ccb1d637424c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Lakshmipathi N. (2019) ‘IMDB Dataset of 50K Movie Reviews’. Available at: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews (Accessed: 14 April 2025).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a418c-98d6-46d5-b223-7b03b6dc0221",
   "metadata": {},
   "source": [
    "# **Preinstalling Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d0ccd1-7429-446a-8994-c27798193475",
   "metadata": {},
   "source": [
    "Run once and restart the kernel. Do not run again, and continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2d1015-af6e-4e44-a694-76b1edce7fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\alamr\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from gensim) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from gensim) (2.0.9)\n",
      "Requirement already satisfied: pandas in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.3)\n",
      "Requirement already satisfied: pyfume in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: simpful==2.12.0 in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.12.0)\n",
      "Requirement already satisfied: fst-pso==1.8.1 in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: miniful in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from fst-pso==1.8.1->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alamr\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d018d4-169b-46b8-9791-f6a6238b622c",
   "metadata": {},
   "source": [
    "# **Preprocessing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e55ec8-b5ae-4307-b9f1-b17731cc0716",
   "metadata": {},
   "source": [
    "Importing core python libraries\n",
    "*   pandas for dataset manipulation\n",
    "*   numpy for mathematical processes\n",
    "*   pyplot and seaborn for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc45776-98cb-40ee-8b1f-0c892c072b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "nlp_dataset = pd.read_csv(\"./datasets/IMDB Dataset.csv\")\n",
    "nlp_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf763cf-97b1-4fca-baeb-53896417fa60",
   "metadata": {},
   "source": [
    "Display general information breakdown of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8941e364-6f79-42dc-8bc3-c9f48c80ffc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describes basic information regarding the dataset\n",
    "nlp_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1265ae6d-acc0-41f6-b41d-ed2a2777a9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# indicates datatyes of the various data columns\n",
    "nlp_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81749c-ade3-44c4-bbb2-274bf196ded0",
   "metadata": {},
   "source": [
    "Reviewing the dataset structure for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3df0e50-a521-4986-8df2-d5abe58ce7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b95406-6f12-483b-8b29-2e4fdd140d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks for null values in the dataset\n",
    "nlp_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625f5ebc-fbad-4d76-bc55-34a1e0648b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_dataset.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3178d-833b-4995-8e8b-8d0c4816b95f",
   "metadata": {},
   "source": [
    "Checking for duplicates and removing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c5cd37c-04a5-4a64-b987-a36e0e0e6269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks for duplicate values in the dataset\n",
    "nlp_dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baea8111-9b63-4961-a510-452798ac32ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removes existing duplicates\n",
    "nlp_dataset.drop_duplicates(inplace=True)\n",
    "nlp_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696fe881-aabf-4cb4-8101-3df1bfbb203a",
   "metadata": {},
   "source": [
    "# **Deep Learning Model Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d738fc-00b8-4be1-a477-6d8db0dec313",
   "metadata": {},
   "source": [
    "Importing and downloading all the necessary libraries to tokenise the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9b78eb-1d13-4742-b2fc-66236c6652f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alamr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alamr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Alamr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Alamr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Alamr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular Expressions Library to Clean the data\n",
    "import re\n",
    "# Natural Language Toolkit Library to Preprocess the data\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Downhload the necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e4584-6be0-46c2-ad06-105ccb368b82",
   "metadata": {},
   "source": [
    "Function to determine the part-of-speech(POS) tag for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0b4e3df-5367-4830-b13d-91ac4b6889ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "  tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "  # post_tag access = [Tupple][POS Tag][First Letter POS Tag]\n",
    "  tag_dict = {\n",
    "      \"J\": wordnet.ADJ, # Adjectives\n",
    "      \"N\": wordnet.NOUN, # Nouns\n",
    "      \"V\": wordnet.VERB, # Verbs\n",
    "      \"R\": wordnet.ADV # Adverb\n",
    "      }\n",
    "  return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f89b9-081f-4b22-9281-126d6b6160a3",
   "metadata": {},
   "source": [
    "Cleaning the dataset\n",
    "*   Turning each word to lower case\n",
    "*   Removing HTML tags\n",
    "*   Tokenising the words\n",
    "*   Removing Stopwords\n",
    "*   Applying lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "217b4f1f-4ef3-402b-8e41-79834696c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts review into a token\n",
    "def preprocess_text(review):\n",
    "  review = review.lower()\n",
    "  review = re.sub(r'<[^>]+>', '', review)\n",
    "  review = re.sub(r'[^a-zA-Z0-9]', ' ', review)\n",
    "  tokens = word_tokenize(review)\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  tokens = [word for word in tokens if word not in stop_words]\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokens]\n",
    "\n",
    "  return \" \" .join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b03dcf5-101d-4bd7-87c2-b34e726a82f8",
   "metadata": {},
   "source": [
    "Extracting the tokens of the review and target labels as binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca8dcab-e27d-48d2-9948-e0cb04008a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    one reviewer mention watch 1 oz episode hooked...\n",
      "1    wonderful little production film technique una...\n",
      "2    thought wonderful way spend time hot summer we...\n",
      "3    basically family little boy jake think zombie ...\n",
      "4    petter mattei love time money visually stun fi...\n",
      "dtype: object\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nlp_tokenised_reviews = []\n",
    "nlp_sentiment_labels = []\n",
    "\n",
    "def extractTokenisedReview(row):\n",
    "    return preprocess_text(row['review'])\n",
    "    \n",
    "def extractSentimentLabels(row):\n",
    "    if row['sentiment'] == 'positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "nlp_tokenised_reviews = nlp_dataset.apply(extractTokenisedReview, axis=1)\n",
    "nlp_sentiment_labels = nlp_dataset.apply(extractSentimentLabels, axis=1)\n",
    "\n",
    "# example of conversion from review to token\n",
    "print(nlp_tokenised_reviews[:5])\n",
    "print(nlp_sentiment_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e10d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "word2vec_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c699ff-3ca5-439d-8505-f2445ebcdcb9",
   "metadata": {},
   "source": [
    "Function to generate numerical representation (embedding) for a string of tokens from a review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bff5387-daaf-47f5-a28e-a369dc4b4397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence, model, vector_size = 300, max_len = 10):\n",
    "  tokens = sentence.split()\n",
    "  # Storing the numerical vectors of the tokens that are valid\n",
    "  token_vectors = []\n",
    "  valid_tokens = [token for token in tokens if token in model.key_to_index]\n",
    "  # Returning a zero vector if no valid tokens are found\n",
    "  if not valid_tokens:\n",
    "    return np.zeros(vector_size)\n",
    "  for token in valid_tokens:\n",
    "    if token in model.key_to_index:\n",
    "      token_vectors.append(model[token])\n",
    "  # Padding to fix the length\n",
    "  if len(token_vectors) < max_len:\n",
    "    padding = [np.zeros(vector_size)] * (max_len - len(token_vectors))\n",
    "    token_vectors.extend(padding)\n",
    "  else:\n",
    "    token_vectors = token_vectors[:max_len]\n",
    "\n",
    "  # Returning the embeddings\n",
    "  return np.array(token_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344f3ec-bb8f-4a55-b6a6-9fa534338c8b",
   "metadata": {},
   "source": [
    "Extracting the embeddings for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cc28cf3-b307-42ce-9591-72a239a6b532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49582, 10, 300)\n",
      "(49582,)\n"
     ]
    }
   ],
   "source": [
    "nlp_embeddings = []\n",
    "for review in nlp_tokenised_reviews:\n",
    "  sentence_embedding = get_sentence_embedding(review, word2vec_model)\n",
    "  nlp_embeddings.append(sentence_embedding)\n",
    "#  Converting the embeddings and sentiment binary labels to NumPy array for the ML Model\n",
    "nlp_embeddings = np.array(nlp_embeddings)\n",
    "nlp_sentiment_labels = np.array(nlp_sentiment_labels)\n",
    "print(nlp_embeddings.shape)\n",
    "print(nlp_sentiment_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6df9e8c5-3a69-4bb7-b173-eb289dcafa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 100\n",
    "VECTOR_SIZE = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6566e15-c7bc-4883-ab97-d0aa48e75bc9",
   "metadata": {},
   "source": [
    "## **Recurrent Neural Network (RNN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3872d6-fe52-4a48-98a8-818399a744d0",
   "metadata": {},
   "source": [
    "## **Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9432db-85af-4529-9941-43e26c5546a4",
   "metadata": {},
   "source": [
    "# **Evaluation and Insights**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
